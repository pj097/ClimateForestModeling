{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc611d4-bd39-465c-8ad1-162c494f92e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_CPP_MIN_LOG_LEVEL=3\n"
     ]
    }
   ],
   "source": [
    "%env TF_CPP_MIN_LOG_LEVEL=3\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from importlib import reload\n",
    "import keras_model_creator\n",
    "import sentinel_utils\n",
    "import plot_utils\n",
    "from data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578c9f40-25ef-49e9-a4e4-11bde389fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentinel_bands = [f'B{x}' for x in range(2, 9)] + ['B8A', 'B11', 'B12']\n",
    "# shards_dir = Path.home().joinpath('sentinel_data', 'shards')\n",
    "# indices = [sentinel_bands.index(b) for b in ['B3', 'B8', 'B6', 'B11']]\n",
    "# shards = list(shards_dir.joinpath('features_201706').glob('feature*.npy'))\n",
    "# for shard in tqdm(shards):\n",
    "#     data = np.copy(np.load(shard))\n",
    "#     np.save(\n",
    "#         shards_dir.joinpath('features_2017', shard.stem),\n",
    "#         data[..., indices]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d4be11-8df6-424a-902b-1eb7820d10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(sentinel_utils)\n",
    "\n",
    "model_dir = Path('models', 'selected_model')\n",
    "shards_dir = Path.home().joinpath('sentinel_data', 'shards')\n",
    "\n",
    "utils = sentinel_utils.SentinelUtils(min_occurrences=20000)\n",
    "\n",
    "selected_classes = utils.get_processed_labels()\n",
    "\n",
    "data_summary = utils.get_data_summary(\n",
    "    shards_dir, selected_classes, overwrite_existing=False\n",
    ")\n",
    "\n",
    "loss = 'binary_crossentropy'\n",
    "batch_size = 64\n",
    "base_filters = 32\n",
    "\n",
    "model_parent_dir = Path('models')\n",
    "model_dir = model_parent_dir.joinpath(\n",
    "    f'{loss}-{len(selected_classes.index)}'\n",
    "    f'-{selected_classes.shape[1]}-{batch_size}-{base_filters}'\n",
    ")\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "params = dict(\n",
    "    loss=loss,\n",
    "    base_filters=base_filters,\n",
    "    shards_dir=shards_dir,\n",
    "    selected_classes=selected_classes,\n",
    "    data_summary=data_summary,\n",
    "    batch_size=64,\n",
    "    dropout=0.5,\n",
    "    model_dir=model_dir,\n",
    "    epochs=30,\n",
    "    overwrite=False,\n",
    "    verbose=1,\n",
    "    print_log=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5474a85-ef57-407b-a568-6fb6b940958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722537992.436603   13847 service.cc:145] XLA service 0x7f8f70002590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722537992.436653   13847 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti, Compute Capability 8.9\n",
      "I0000 00:00:1722538004.820807   13847 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3550/3550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4979 - auc: 0.9047 - loss: 0.3236 - macrof1score: 0.4606 - microf1score: 0.6813 - prc: 0.7691 - precision: 0.7588 - recall: 0.6181 - weightedf1score: 0.6339\n",
      "Epoch 11: val_recall improved from 0.50000 to 0.63638, saving model to models/binary_crossentropy-237212-7-64-32/model.keras\n",
      "\u001b[1m3550/3550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 64ms/step - accuracy: 0.4979 - auc: 0.9047 - loss: 0.3236 - macrof1score: 0.4606 - microf1score: 0.6813 - prc: 0.7691 - precision: 0.7588 - recall: 0.6181 - weightedf1score: 0.6339 - val_accuracy: 0.5288 - val_auc: 0.9200 - val_loss: 0.3000 - val_macrof1score: 0.4900 - val_microf1score: 0.7036 - val_prc: 0.8049 - val_precision: 0.7867 - val_recall: 0.6364 - val_weightedf1score: 0.6581 - learning_rate: 2.5000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m3550/3550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5007 - auc: 0.9057 - loss: 0.3217 - macrof1score: 0.4626 - microf1score: 0.6834 - prc: 0.7719 - precision: 0.7584 - recall: 0.6219 - weightedf1score: 0.6367\n",
      "Epoch 12: val_recall improved from 0.63638 to 0.63655, saving model to models/binary_crossentropy-237212-7-64-32/model.keras\n",
      "\u001b[1m3550/3550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 49ms/step - accuracy: 0.5007 - auc: 0.9057 - loss: 0.3217 - macrof1score: 0.4626 - microf1score: 0.6834 - prc: 0.7719 - precision: 0.7584 - recall: 0.6219 - weightedf1score: 0.6367 - val_accuracy: 0.5246 - val_auc: 0.9190 - val_loss: 0.3006 - val_macrof1score: 0.4964 - val_microf1score: 0.7050 - val_prc: 0.8031 - val_precision: 0.7899 - val_recall: 0.6366 - val_weightedf1score: 0.6637 - learning_rate: 2.5000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m3550/3550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5005 - auc: 0.9054 - loss: 0.3222 - macrof1score: 0.4608 - microf1score: 0.6815 - prc: 0.7708 - precision: 0.7571 - recall: 0.6196 - weightedf1score: 0.6349\n",
      "Epoch 13: val_recall did not improve from 0.63655\n",
      "\u001b[1m3550/3550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 49ms/step - accuracy: 0.5005 - auc: 0.9054 - loss: 0.3222 - macrof1score: 0.4608 - microf1score: 0.6815 - prc: 0.7708 - precision: 0.7571 - recall: 0.6196 - weightedf1score: 0.6349 - val_accuracy: 0.5312 - val_auc: 0.9191 - val_loss: 0.3025 - val_macrof1score: 0.4741 - val_microf1score: 0.6925 - val_prc: 0.8010 - val_precision: 0.7920 - val_recall: 0.6152 - val_weightedf1score: 0.6435 - learning_rate: 2.5000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m2169/3550\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 52ms/step - accuracy: 0.4978 - auc: 0.9064 - loss: 0.3215 - macrof1score: 0.4638 - microf1score: 0.6843 - prc: 0.7723 - precision: 0.7585 - recall: 0.6234 - weightedf1score: 0.6376"
     ]
    }
   ],
   "source": [
    "reload(keras_model_creator)\n",
    "model, testing_generator = keras_model_creator.KerasModelCreator(**params).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5da23-ab39-4f18-aa6a-b249e4beadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e4320-e4fe-41f2-95ef-74268cf2479c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b338c2a0-5c4e-4c59-acd4-25f2a07358a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79e0bb-81e2-4f5c-8a37-4d3b30829417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
