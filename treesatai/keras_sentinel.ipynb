{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a09dcb-b90b-45d7-b5a2-54996a34ada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 12:52:14.683660: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-15 12:52:16.018371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import intake\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, Activation, BatchNormalization, \\\n",
    "                                     Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17759222-56d5-4a21-ba7d-c508b05ea21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = intake.open_catalog(Path('../catalog.yml'))\n",
    "source = getattr(catalog, 'treesat')\n",
    "df = source.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0749fbd3-b6ee-443c-b12c-741c2ee1f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_bands = [f'B{x}' for x in range(2, 9)] + ['B8A', 'B11', 'B12', 'TCI_R', 'TCI_G', 'TCI_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5fb97e-b021-4620-9b31-468323822101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3DModelCreator:\n",
    "    def normalise(self, a, p=1):\n",
    "        upper = np.percentile(a, 100-p)\n",
    "        lower = np.percentile(a, p)\n",
    "    \n",
    "        bounded_a = np.where(a > upper, np.median(a), a)\n",
    "        bounded_a = np.where(a < lower, np.median(a), bounded_a)\n",
    "        \n",
    "        scaled_a = (bounded_a - lower)/(upper - lower)\n",
    "        return scaled_a\n",
    "        \n",
    "    def split_and_preprocess(self, y, X, random_state=42):\n",
    "        \"\"\"Split and max scale.\"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.1, random_state=random_state)\n",
    "        \n",
    "        X_train = self.normalise(X_train)\n",
    "\n",
    "        X_test = self.normalise(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def build_model_3d(self, num_classes, input_size):\n",
    "        m = tf.keras.Sequential()\n",
    "        m.add(Input(input_size))\n",
    "        for i in range(3): \n",
    "            m.add(Conv3D(\n",
    "                32, kernel_size=(3, 3, 3), \n",
    "                strides=1, padding='same',\n",
    "                kernel_initializer='he_normal',\n",
    "                kernel_regularizer=l2(1e-6)\n",
    "            ))\n",
    "            m.add(BatchNormalization(axis=-1))\n",
    "            m.add(Activation('relu'))\n",
    "            m.add(Dropout(0.25))\n",
    "            \n",
    "        m.add(Flatten())\n",
    "\n",
    "        m.add(Dense(64, kernel_initializer='he_normal', \n",
    "                  kernel_regularizer=l2(1e-6)))\n",
    "        m.add(BatchNormalization(axis=-1))\n",
    "        m.add(Activation('relu'))\n",
    "        m.add(Dropout(0.25))\n",
    "        m.add(Dense(\n",
    "            num_classes, activation='softmax', \n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(1.e-6)\n",
    "        ))\n",
    "        \n",
    "        m.compile(\n",
    "            optimizer='adam',\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return m\n",
    "        \n",
    "    def run(self, y, X, model_name, overwrite=False):\n",
    "        X_train, X_test, y_train, y_test = self.split_and_preprocess(y, X)\n",
    "        model_path = Path('models').joinpath(model_name)\n",
    "\n",
    "        if model_path.is_file() and not overwrite:\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "        else:\n",
    "            model = self.build_model_3d(np.unique(y).size, X_train.shape[1:])\n",
    "            model.fit(X_train, y_train, epochs=10, verbose=1, batch_size=4)\n",
    "            model.save(model_path)\n",
    "              \n",
    "        return model.evaluate(X_test, y_test, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e930bc4-4c27-4992-b2c3-6f0180070568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9244375228881836, 0.7074816226959229]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = source.metadata['categories']['multi'] # multi / trinary\n",
    "labels = df[target].astype('category').cat.codes\n",
    "all_data = []\n",
    "\n",
    "filepaths = sorted(list(Path('seasonal_median').glob(f'processed*3.npy')))\n",
    "for filepath in filepaths:\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = np.load(f)\n",
    "    all_data.append(data)\n",
    "    \n",
    "model_name = f'conv_all_springs_multi.keras'\n",
    "\n",
    "features = np.stack(all_data, axis=3)\n",
    "score = Conv3DModelCreator().run(labels, features, model_name, overwrite=False)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36e076-dd61-4d3b-a2f1-d6a5a08db93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8a5ee-1b88-4023-aab6-b17436811e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888d439-d3fd-469a-8695-817171de1ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeb40e4b-059f-4dda-b602-d603e1c22f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = source.metadata['categories']['multi'] # multi / trinary\n",
    "# labels = df[target].astype('category').cat.codes\n",
    "# seasons = ['Spring', 'Summer', 'Autumn', 'Winter']\n",
    "# all_data = []\n",
    "# for season in seasons:\n",
    "#     filepath = sorted(list(Path('seasonal_median').glob(f'{season}.npy')))\n",
    "#     with open(filepath[0], 'rb') as f:\n",
    "#         all_data.append(np.load(f))\n",
    "    \n",
    "# model_name = f'conv_all_mean_seasons_multi.keras'\n",
    "\n",
    "# features = np.stack(all_data, axis=3)\n",
    "# score = ConvModelCreator().run(labels, features, model_name)\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f4c44e9-a2d6-4cb7-ba97-869f17f9733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traces = [go.Scatter(x=seasons, y=seasonal_scores)]\n",
    "# go.Figure(\n",
    "#     data=traces,\n",
    "#     layout={\n",
    "#         \"xaxis\": {\"title\": \"Season\"},\n",
    "#         \"yaxis\": {\"title\": \"Accuracy\"},\n",
    "#         \"title\": \"Conv2d accuracies\"}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343067ff-97a9-46a6-8d85-b553a792dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = source.metadata['categories']['trinary'] # multi / trinary\n",
    "# labels = df[target].astype('category').cat.codes\n",
    "# seasons = ['Spring', 'Summer', 'Autumn', 'Winter']\n",
    "# all_data = []\n",
    "# for season in tqdm(seasons):\n",
    "#     filepath = sorted(list(Path('seasonal_median').glob(f'{season}.npy')))\n",
    "#     with open(filepath[0], 'rb') as f:\n",
    "#         all_data.append(np.load(f))\n",
    "    \n",
    "# model_name = f'conv_all_mean_seasons_trinary.keras'\n",
    "# score = ConvModelCreator().run(labels, np.stack(all_data, axis=3), model_name)\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49338456-9905-4cef-bf76-db246dc84d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = source.metadata['categories']['trinary'] # multi / trinary\n",
    "\n",
    "# mask = df[target] != 'cleared'\n",
    "\n",
    "# labels = df[target][mask].astype('category').cat.codes\n",
    "\n",
    "# seasons = ['Spring', 'Summer', 'Autumn', 'Winter']\n",
    "# all_data = []\n",
    "# for season in tqdm(seasons):\n",
    "#     filepath = sorted(list(Path('seasonal_median').glob(f'{season}.npy')))\n",
    "#     with open(filepath[0], 'rb') as f:\n",
    "#         data = np.load(f)\n",
    "#         all_data.append(data[mask])\n",
    "        \n",
    "# model_name = f'conv_all_mean_seasons_binary.keras'\n",
    "# score = ConvModelCreator().run(labels, np.stack(all_data, axis=3), model_name)\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f8aaa-cc12-44e2-a887-9d8af6b5fef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40222121-e554-4334-8698-f86951553aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = sorted(list(Path('london').glob('*.npy')), key=lambda x: int(x.stem.split('_')[-1]))\n",
    "\n",
    "# n_chunks = 50000\n",
    "# chunks = [gdf[i: i + n_chunks] for i in range(0, gdf.shape[0], n_chunks)]\n",
    "# scores = []\n",
    "\n",
    "# chunk[target].cat.codes\n",
    "\n",
    "# for chunk, filepath in tqdm(zip(chunks, filepaths), total=len(filepaths)\n",
    "#                            ):\n",
    "#     score = LightModelCreator().run_and_eval(chunk[target].cat.codes, [filepath])\n",
    "#     scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82157b0b-aa81-48ee-a15a-6a533370c3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156bde7-a279-465b-9c62-a9c34ae0f829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a1dee-1b34-4cbd-8037-37702377a9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a88adb-eca0-44ba-9b83-49adb7994137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dfa99c-b32b-4bb5-8994-2b54acbe439f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee6c92-f989-4253-b7de-08a50c4e40cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5189141-5f07-4aac-a68f-00a24ec5d69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3378d43-42ae-4f34-9df2-6e74e58f1822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
