{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a09dcb-b90b-45d7-b5a2-54996a34ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import intake\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17759222-56d5-4a21-ba7d-c508b05ea21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = intake.open_catalog(Path('../catalog.yml'))\n",
    "source = getattr(catalog, 'treesat')\n",
    "gdf = source.read()[source.metadata['usecols']]\n",
    "gdf.crs = 25832\n",
    "gdf = gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626019d0-f07b-4e8f-92c4-0d4d2d4c42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = source.metadata['categories']['generic']\n",
    "gdf[target] = gdf[target].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0749fbd3-b6ee-443c-b12c-741c2ee1f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_bands = [f'B{x}' for x in range(2, 9)] + ['B8A', 'B11', 'B12', 'TCI_R', 'TCI_G', 'TCI_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5fb97e-b021-4620-9b31-468323822101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasModelCreator:\n",
    "    def __init__(self):\n",
    "        self.zeros = {}\n",
    "        \n",
    "    def load_and_fill_data(self, filepath):\n",
    "        \"\"\"Load numpy files and replace masks with the mean.\"\"\"\n",
    "        print(f'Loading {filepath}')\n",
    "        with open(filepath, 'rb') as f:\n",
    "            a = np.load(f)\n",
    "            \n",
    "        data_array = np.array(a.tolist()).reshape(len(a), -1)\n",
    "\n",
    "        self.zeros[filepath.stem] = 100*(data_array == 0).sum()/data_array.size\n",
    "        print(f'{self.zeros[filepath.stem]:.1f}% of dataset is masked.')\n",
    "        nonzero_mean = data_array[data_array > 0].mean()\n",
    "        return np.where(data_array > 0, data_array, nonzero_mean)\n",
    "\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def fit_eval(self, y, X, array_key, random_state=42):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.1, random_state=random_state)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        model = self.build_model()\n",
    "        \n",
    "        print(f'Fitting {array_key}...')\n",
    "        model.fit(X_train, y_train, epochs=10, verbose=0)\n",
    "        print(f'Evaluating {array_key}...')\n",
    "        model.evaluate(X_test, y_test, verbose=2)\n",
    "        \n",
    "    \n",
    "    def run(self, gdf, filepaths, individual=True, combined=False, chunk_keys=None):\n",
    "        labels = gdf[target].cat.codes.to_numpy()\n",
    "        report_dfs = {}\n",
    "        data_dict = {}\n",
    "        for filepath in filepaths:\n",
    "            array_key = filepath.stem\n",
    "            data_array = self.load_and_fill_data(filepath)\n",
    "            \n",
    "            data_dict[array_key] = data_array\n",
    "            \n",
    "            if individual:\n",
    "                self.fit_eval(labels, data_array, array_key)\n",
    "        \n",
    "        if chunk_keys:\n",
    "            chunk = np.mean([data_dict[k] for k in chunk_keys], axis=0)\n",
    "            self.fit_eval(labels, chunk, array_key)\n",
    "            \n",
    "            chunk = np.concatenate([data_dict[k] for k in chunk_keys])\n",
    "            y = np.repeat(labels, len(chunk_keys))\n",
    "            self.fit_eval(labels, chunk, array_key)\n",
    "\n",
    "        if combined:\n",
    "            combined_data = np.mean(list(data_dict.values()), axis=0)\n",
    "            self.fit_eval(labels, combined_data, array_key)\n",
    "        \n",
    "            combined_data = np.concatenate(list(data_dict.values()))\n",
    "            y = np.repeat(labels, len(data_dict))\n",
    "            self.fit_eval(labels, combined_data, array_key)\n",
    "        \n",
    "        return self.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c556622-9d11-4368-9327-786914a2703b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\\treesat_012018.npy\n",
      "31.5% of dataset is masked.\n",
      "WARNING:tensorflow:From C:\\Users\\smart\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Fitting treesat_012018...\n",
      "Evaluating treesat_012018...\n",
      "5039/5039 - 0s - loss: 1.8063 - acc: 0.3312\n",
      "Loading data\\treesat_012019.npy\n",
      "5.8% of dataset is masked.\n",
      "Fitting treesat_012019...\n",
      "Evaluating treesat_012019...\n",
      "5039/5039 - 0s - loss: 1.5603 - acc: 0.4372\n",
      "Loading data\\treesat_012020.npy\n",
      "2.8% of dataset is masked.\n",
      "Fitting treesat_012020...\n",
      "Evaluating treesat_012020...\n",
      "5039/5039 - 0s - loss: 1.5709 - acc: 0.4487\n",
      "Loading data\\treesat_012021.npy\n",
      "23.5% of dataset is masked.\n",
      "Fitting treesat_012021...\n",
      "Evaluating treesat_012021...\n",
      "5039/5039 - 0s - loss: 1.7323 - acc: 0.3663\n",
      "Loading data\\treesat_012022.npy\n",
      "0.0% of dataset is masked.\n",
      "Fitting treesat_012022...\n",
      "Evaluating treesat_012022...\n",
      "5039/5039 - 0s - loss: 1.8602 - acc: 0.3362\n",
      "Loading data\\treesat_012023.npy\n",
      "0.0% of dataset is masked.\n",
      "Fitting treesat_012023...\n",
      "Evaluating treesat_012023...\n",
      "5039/5039 - 0s - loss: 1.8732 - acc: 0.3386\n",
      "Loading data\\treesat_022018.npy\n",
      "3.5% of dataset is masked.\n",
      "Fitting treesat_022018...\n",
      "Evaluating treesat_022018...\n",
      "5039/5039 - 0s - loss: 1.3149 - acc: 0.5162\n",
      "Loading data\\treesat_022019.npy\n",
      "0.0% of dataset is masked.\n",
      "Fitting treesat_022019...\n",
      "Evaluating treesat_022019...\n",
      "5039/5039 - 0s - loss: 1.2565 - acc: 0.5618\n",
      "Loading data\\treesat_022020.npy\n",
      "38.6% of dataset is masked.\n",
      "Fitting treesat_022020...\n",
      "Evaluating treesat_022020...\n",
      "5039/5039 - 0s - loss: 1.8792 - acc: 0.2997\n",
      "Loading data\\treesat_022021.npy\n",
      "0.0% of dataset is masked.\n",
      "Fitting treesat_022021...\n",
      "Evaluating treesat_022021...\n",
      "5039/5039 - 0s - loss: 1.3289 - acc: 0.5158\n",
      "Loading data\\treesat_022022.npy\n",
      "0.0% of dataset is masked.\n",
      "Fitting treesat_022022...\n",
      "Evaluating treesat_022022...\n",
      "5039/5039 - 0s - loss: 1.5108 - acc: 0.4711\n",
      "Loading data\\treesat_022023.npy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# filepaths = [Path('data').joinpath('treesat_042019.npy')]\n",
    "filepaths = Path('data').glob('treesat_*.npy')\n",
    "report_dfs = KerasModelCreator().run(\n",
    "    gdf, filepaths, individual=True, combined=False, chunk_keys=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe033c6-69c4-4913-bb4b-2b845f9685bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a3066-469e-4543-981c-79c7037baf51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ffa18f-41d5-49c0-9b28-188b6424d0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8914e0-36c5-46cd-9924-ec282dfc2b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da89d4-ad43-43f4-966b-784ce1563181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb2ae7-7262-4f72-a27e-5dbe021caf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee6c92-f989-4253-b7de-08a50c4e40cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5189141-5f07-4aac-a68f-00a24ec5d69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3378d43-42ae-4f34-9df2-6e74e58f1822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
