{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f332c8-e367-4026-94e1-5b0f5f0a35db",
   "metadata": {},
   "source": [
    "##### **Run LGBM data exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a09dcb-b90b-45d7-b5a2-54996a34ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import intake\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import lightgbm\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210019ca-901f-4de1-acc8-a133599aaf8f",
   "metadata": {},
   "source": [
    "Read in data and ensure correct CRS. Alternatively, use Geopandas directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17759222-56d5-4a21-ba7d-c508b05ea21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = intake.open_catalog(Path('../catalog.yml'))\n",
    "source = getattr(catalog, 'treesat')\n",
    "gdf = source.read()[source.metadata['usecols']]\n",
    "gdf.crs = 25832\n",
    "gdf = gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e6947c-b684-4ae7-b95e-aeaa8d449168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi (e.g. oak, spruce...) or trinary (broadleaf, needleleaf, cleared)\n",
    "target = source.metadata['categories']['multi'] \n",
    "gdf[target] = gdf[target].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0749fbd3-b6ee-443c-b12c-741c2ee1f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 bands will be used: ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12', 'TCI_R', 'TCI_G', 'TCI_B']\n"
     ]
    }
   ],
   "source": [
    "selected_bands = [f'B{x}' for x in range(2, 9)] + ['B8A', 'B11', 'B12', 'TCI_R', 'TCI_G', 'TCI_B']\n",
    "print(f'{len(selected_bands)} bands will be used: {selected_bands}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc54046-9d55-4154-b864-bdd78c9ee2aa",
   "metadata": {},
   "source": [
    "LightGBM is a gradient boosting estimator that uses tree based learning algorithms. It is designed for better performance while maintaining or improving accuracy. It is ideal for exploring the large amounts of data generated by Sentinel-2. \n",
    "\n",
    "For more information: https://lightgbm.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5fb97e-b021-4620-9b31-468323822101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightModelCreator:\n",
    "    '''\n",
    "    Use Scitkit-learn's OneVsRestClassifier to fit one\n",
    "    LGBM classifier per class and return accuracy scores.\n",
    "    '''\n",
    "    def train(self, X_train, y_train):\n",
    "        params = dict(\n",
    "            verbose=0,\n",
    "            # device_type='gpu' # does not work within WSL\n",
    "        )\n",
    "        lgb = lightgbm.LGBMClassifier(**params)\n",
    "\n",
    "        stacked_model = OneVsRestClassifier(lgb)\n",
    "        stacked_model.fit(X_train, y_train)\n",
    "        return stacked_model\n",
    "    \n",
    "    def predict(self, X, y, model_name, random_state=42):\n",
    "        X = X.reshape(len(y), -1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.1, random_state=random_state)\n",
    "\n",
    "        model_path = Path('models').joinpath(model_name)\n",
    "        if model_path.is_file():\n",
    "            stacked_model = joblib.load(model_path)\n",
    "        else:\n",
    "            stacked_model = self.train(X_train, y_train)\n",
    "            joblib.dump(stacked_model, model_path)\n",
    "            \n",
    "        y_pred = stacked_model.predict(X_test)\n",
    "\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    def run_and_eval(self, labels, filepaths):\n",
    "        scores = []\n",
    "        for filepath in tqdm(filepaths, leave=False):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                data = np.load(f)\n",
    "                \n",
    "            model_name = f'lgbm_{filepath.parent}_{filepath.stem}.joblib'\n",
    "            scores.append(\n",
    "                self.predict(data, labels, model_name)\n",
    "            )\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7dd04-619c-4d08-be9b-c08e155b0ae3",
   "metadata": {},
   "source": [
    "The final image is a mosaic from a temporal collection of images. A month usually contains about 6 images due to the frequency of the Sentinel-2 satellites. In this case, the images of a given month are reduced using either a temporal mean or a temporal median of the pixel per band. This is done in order to reduce atmospheric variabilities such as cloud covering of the area of interest. \n",
    "\n",
    "The below is slow when first training, but the models are saved for re-use when the notebook is re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1baa7-96a9-4347-a303-2c907c8b8c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59ef799b72147f48e0bd21ddf539853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dfdb78c48843ffa89ae441af9dce48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traces = []\n",
    "monthly_scores = []\n",
    "months = list(range(1, 13))\n",
    "for method in tqdm(['mean', 'median']):\n",
    "    filepaths = sorted(list(Path(f'data_{method}').glob(f'processed_treesat_2019*.npy')))\n",
    "    scores = LightModelCreator().run_and_eval(gdf[target].cat.codes, filepaths)\n",
    "    monthly_scores.extend(scores)\n",
    "    traces.append(go.Scatter(x=months, y=scores, name=method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8914e0-36c5-46cd-9924-ec282dfc2b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "go.Figure(\n",
    "    data=traces,\n",
    "    layout={\n",
    "        \"xaxis\": {\"title\": \"Month\"},\n",
    "        \"yaxis\": {\"title\": \"Accuracy\"},\n",
    "        \"title\": \"LGBM accuracies for 2019\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64aabd-637c-4f8f-ac7f-98fd994e33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = sum(monthly_scores)/len(monthly_scores)\n",
    "print(f'Monthly accuracy scores range from {min(monthly_scores):.2f} to {max(monthly_scores):.2f}, with an average accuracy of {mean:.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9286b8-34fd-4278-bba8-c2aff3e00376",
   "metadata": {},
   "source": [
    "The median appears to produce better results. As such, it is be used in subsequent analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e58c7-0b6c-446a-9b24-9cf0f3327e97",
   "metadata": {},
   "source": [
    "Next, perform a similar exploration for the processed seasonal data.\n",
    "\n",
    "The seasons are taken as:\n",
    "- winter: December, January, February\n",
    "- spring: March, April, May\n",
    "- summer: June, July, August\n",
    "- autumn: September, October, November\n",
    "\n",
    "The seasonal data and the median monthly data were processed similarly, with the exception that the seasonal data covers the 3 months of the corresponding season instead of 1 month like the monthly data.\n",
    "\n",
    "As before, the processing below is slow when first training, but the models are saved for re-use when the notebook is re-run, which should be substantially faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a5f76-82a1-4567-8e81-49822f0f51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "seasons = ['Spring', 'Summer', 'Autumn', 'Winter']\n",
    "seasonal_scores = []\n",
    "for year in tqdm(range(2017, 2024)):\n",
    "    filepaths = sorted(list(Path('seasonal_median').glob(f'processed*{year}*.npy')))\n",
    "    scores = LightModelCreator().run_and_eval(gdf[target].cat.codes, filepaths)\n",
    "    seasonal_scores.extend(scores)\n",
    "    traces.append(go.Scatter(\n",
    "        x=seasons, y=scores, name=year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3378d43-42ae-4f34-9df2-6e74e58f1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "go.Figure(\n",
    "    data=traces,\n",
    "    layout={\n",
    "        \"xaxis\": {\"title\": \"Season\"},\n",
    "        \"yaxis\": {\"title\": \"Accuracy\"},\n",
    "        \"title\": \"LGBM accuracies\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034d0f0-5db9-4218-b450-37d013ee1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = sum(seasonal_scores)/len(seasonal_scores)\n",
    "print(f'Seasonal accuracy scores range from {min(seasonal_scores):.2f} to {max(seasonal_scores):.2f}, with an average accuracy of {mean:.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe591de1-8d8b-4e85-a8a0-9ea59c273f9c",
   "metadata": {},
   "source": [
    "This indicates a significant improvement when compared to the monthly approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9134ee60-2ad0-45d5-9019-3dc9d15b526c",
   "metadata": {},
   "source": [
    "And using combined seasons across all years available (2017 to 2023 inclusive):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8783603-51c0-4e89-a794-fc22d94c93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = ['Spring', 'Summer', 'Autumn', 'Winter']\n",
    "mean_seasonal_scores = []\n",
    "for season in tqdm(seasons):\n",
    "    filepath = sorted(list(Path('seasonal_median').glob(f'{season}.npy')))\n",
    "    score = LightModelCreator().run_and_eval(gdf[target].cat.codes, filepath)\n",
    "    mean_seasonal_scores.extend(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d946c-1e28-4de0-b1be-9382ec69cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [go.Scatter(x=seasons, y=mean_seasonal_scores)]\n",
    "go.Figure(\n",
    "    data=traces,\n",
    "    layout={\n",
    "        \"xaxis\": {\"title\": \"Season\"},\n",
    "        \"yaxis\": {\"title\": \"Accuracy\"},\n",
    "        \"title\": \"LGBM accuracies\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651642ea-d3bc-492d-baea-18c0cd3b693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = sum(mean_seasonal_scores)/len(mean_seasonal_scores)\n",
    "print(f'Mean seasonal accuracy scores range from {min(mean_seasonal_scores):.2f} to {max(mean_seasonal_scores):.2f}, with an average accuracy of {mean:.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56235d3e-24ca-4b6a-a878-7f465930ee4e",
   "metadata": {},
   "source": [
    "A seasonal mean across all years available indicates a further improvement when compared to using individual seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e3d06-a158-4ea3-bc06-dd835e7c0e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7b4fc-8bf3-4ac0-b98b-bbc9801de270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
