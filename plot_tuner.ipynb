{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441015c0-2702-40ea-a3e9-3f1a61be0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import ImageFont, Image\n",
    "import visualkeras\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "\n",
    "import hyper_model_creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275f106d-b4d0-4363-a945-a806e0f005dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = Path('report', 'figures', 'figures_tuner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0540fbb-c399-4a3e-a380-f3fe7c75bb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from trials/hyperband_resnet/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "trials_dir = Path('trials', 'hyperband_resnet_followup')\n",
    "trials_metric = 'val_weightedf2score'\n",
    "hypermodel = hyper_model_creator.BuildHyperModel(trials_dir, trials_metric)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel,\n",
    "    objective=kt.Objective(trials_metric, direction='max'),\n",
    "    directory=trials_dir.parent,\n",
    "    project_name=trials_dir.name,\n",
    ")\n",
    "hp = tuner.oracle.get_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bcf1ebd-714d-4a7d-95e4-824483ba127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 102 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A total of 15 objects could not be loaded. Example error message for object <Conv2D name=conv2d_12, built=True>:\n\nLayer 'conv2d_12' expected 2 variables, but received 0 variables during loading. Expected: ['kernel', 'bias']\n\nList of objects that could not be loaded:\n[<Conv2D name=conv2d_12, built=True>, <BatchNormalization name=batch_normalization_8, built=True>, <Conv2D name=conv2d_13, built=True>, <Conv2D name=conv2d_15, built=True>, <Conv2D name=conv2d_14, built=True>, <BatchNormalization name=batch_normalization_9, built=True>, <Dense name=dense, built=True>, <BatchNormalization name=batch_normalization_10, built=True>, <Dense name=dense_1, built=True>, <BatchNormalization name=batch_normalization_11, built=True>, <Dense name=dense_2, built=True>, <BatchNormalization name=batch_normalization_12, built=True>, <Dense name=dense_3, built=True>, <BatchNormalization name=batch_normalization_13, built=True>, <Dense name=dense_4, built=True>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:400\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:366\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[0;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(trial) \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:366\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[0;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:320\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[0;32m--> 320\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# Build model to create the weights.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:164\u001b[0m, in \u001b[0;36mTuner._try_build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    161\u001b[0m keras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m    162\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m--> 164\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_hypermodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Stop if `build()` does not return a valid model.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras_tuner/src/tuners/hyperband.py:438\u001b[0m, in \u001b[0;36mHyperband._build_hypermodel\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n\u001b[1;32m    435\u001b[0m         model\u001b[38;5;241m.\u001b[39mbuild_from_config(\n\u001b[1;32m    436\u001b[0m             utils\u001b[38;5;241m.\u001b[39mload_json(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_build_config_fname(trial_id))\n\u001b[1;32m    437\u001b[0m         )\n\u001b[0;32m--> 438\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_checkpoint_fname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:295\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[0;34m(error_msgs, warn_only)\u001b[0m\n\u001b[1;32m    293\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: A total of 15 objects could not be loaded. Example error message for object <Conv2D name=conv2d_12, built=True>:\n\nLayer 'conv2d_12' expected 2 variables, but received 0 variables during loading. Expected: ['kernel', 'bias']\n\nList of objects that could not be loaded:\n[<Conv2D name=conv2d_12, built=True>, <BatchNormalization name=batch_normalization_8, built=True>, <Conv2D name=conv2d_13, built=True>, <Conv2D name=conv2d_15, built=True>, <Conv2D name=conv2d_14, built=True>, <BatchNormalization name=batch_normalization_9, built=True>, <Dense name=dense, built=True>, <BatchNormalization name=batch_normalization_10, built=True>, <Dense name=dense_1, built=True>, <BatchNormalization name=batch_normalization_11, built=True>, <Dense name=dense_2, built=True>, <BatchNormalization name=batch_normalization_12, built=True>, <Dense name=dense_3, built=True>, <BatchNormalization name=batch_normalization_13, built=True>, <Dense name=dense_4, built=True>]"
     ]
    }
   ],
   "source": [
    "tuner.get_best_models(num_models=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483df4f6-e7d8-4f39-9c5f-c05434c85424",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for p in hp.space:\n",
    "    config = p.get_config()\n",
    "    rows.append(config)\n",
    "\n",
    "search_space = pd.DataFrame(rows)[['name', 'values']].fillna('[true, false]').astype('string')\n",
    "for c in search_space.columns: \n",
    "    search_space[c] = search_space[c].str.replace('_', '\\\\_')\n",
    "\n",
    "tex = search_space.to_latex(\n",
    "    index=False,\n",
    "    caption='Summary of initial hyperparameter search space.',\n",
    "    label=f'tab:{trials_dir.name}_params',\n",
    ")\n",
    "tex = tex.split('\\n')\n",
    "tex.insert(3, f'\\centering\\n')\n",
    "\n",
    "with open(figures_dir.joinpath(f'{trials_dir.name}_params.tex'), 'w') as f:\n",
    "    f.write('\\n'.join(tex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2deed91-57b3-497c-865e-7241059eb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for trial in sorted(list(trials_dir.glob('trial_*'))):\n",
    "    with open(trial.joinpath('trial.json')) as f:\n",
    "        results = json.load(f)\n",
    "        row = {'score': results['score']} | results['hyperparameters']['values']\n",
    "        rows.append(row)\n",
    "\n",
    "trials_df = pd.DataFrame(rows).sort_values(by='score', ascending=False)\n",
    "trials_df = trials_df[[c for c in trials_df.columns if 'tuner' not in c]]\n",
    "\n",
    "nrows, ncols = 2, 5\n",
    "fig = make_subplots(\n",
    "    rows=nrows, cols=ncols, shared_yaxes='all', y_title='score',\n",
    "    subplot_titles=trials_df.columns[1:].str.replace('_', '<br>'),\n",
    "    vertical_spacing=0.3,\n",
    ")\n",
    "\n",
    "for i, col in enumerate(trials_df.columns[1:]):\n",
    "    if trials_df[col].dtype == object:\n",
    "        x = trials_df[col].str.replace('_', '<br>')\n",
    "    else:\n",
    "        x = trials_df[col]\n",
    "\n",
    "    position = dict(row=(i//ncols)+1, col=(i%ncols)+1)\n",
    "    fig.append_trace(go.Scatter(\n",
    "        y=trials_df['score'],\n",
    "        x=x,\n",
    "        mode='markers',\n",
    "        marker_size=3,\n",
    "        opacity=0.8,\n",
    "    ), **position)\n",
    "    \n",
    "    fig.append_trace(go.Scatter(\n",
    "        y=[trials_df['score'].max()],\n",
    "        x=[x[trials_df['score'].idxmax()]],\n",
    "        mode='markers',\n",
    "        marker_symbol='diamond-open',\n",
    "        marker_color='red',\n",
    "        marker_size=7,\n",
    "        opacity=0.6,\n",
    "    ), **position)\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        type='log' if 'learning_rate' in col else None,\n",
    "        tickformat='.1r',\n",
    "        tickangle=-60,\n",
    "        tickvals=x.unique(),\n",
    "        **position\n",
    "    )\n",
    "    fig.update_yaxes(range=[0.59, 0.71], tickvals=[0.6, 0.7])\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500, width=700, showlegend=False,\n",
    "    margin=dict(l=80, r=80, t=100, b=80)\n",
    ")\n",
    "fig.write_image(figures_dir.joinpath(f'{trials_dir.name}_params.pdf'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91fbb6-b3c3-4fbe-b45b-739254809064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path('models', 'hypertuned-237212-7-64-2017_2018_2019')\n",
    "model = tf.keras.models.load_model(model_dir.joinpath('model.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af880c7-f0b2-4ef0-96ee-15b485476b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e484b-571a-4ebf-b946-192c46a05fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/paulgavrikov/visualkeras\n",
    "def text_callable(layer_index, layer):\n",
    "    # Every other piece of text is drawn above the layer, the first one below\n",
    "    above = bool(layer_index%2)\n",
    "\n",
    "    # Get the output shape of the layer\n",
    "    output_shape = [x for x in list(layer.output.shape) if x is not None]\n",
    "\n",
    "    # If the output shape is a list of tuples, we only take the first one\n",
    "    if isinstance(output_shape[0], tuple):\n",
    "        output_shape = list(output_shape[0])\n",
    "        output_shape = [x for x in output_shape if x is not None]\n",
    "\n",
    "    # Variable to store text which will be drawn    \n",
    "    output_shape_txt = ''\n",
    "\n",
    "    # Create a string representation of the output shape\n",
    "    for ii in range(len(output_shape)):\n",
    "        output_shape_txt += str(output_shape[ii])\n",
    "        if ii < len(output_shape) - 2: # Add an x between dimensions, e.g. 3x3\n",
    "            output_shape_txt += 'x'\n",
    "        if ii == len(output_shape) - 2: # Add a newline between the last two dimensions, e.g. 3x3 \\n 64\n",
    "            output_shape_txt += '\\n'\n",
    "\n",
    "    # Add the name of the layer to the text, as a new line\n",
    "    layer_name = '\\n'.join(layer.name.split('_')[:2])\n",
    "    output_shape_txt += f'\\n{layer_name}'\n",
    "\n",
    "    # Return the text value and if it should be drawn above the layer\n",
    "    return output_shape_txt, above\n",
    "\n",
    "font = ImageFont.truetype(\n",
    "    '/usr/share/fonts/opentype/freefont/FreeSerifBold.otf',\n",
    "    22, \n",
    "    encoding='unic'\n",
    ")\n",
    "inputs_image = visualkeras.layered_view(\n",
    "    model,\n",
    "    font=font,\n",
    "    padding=70,\n",
    "    index_ignore=range(6, 50),\n",
    "    scale_xy=0.5, \n",
    "    spacing=50,\n",
    "    text_callable=text_callable,\n",
    ")\n",
    "\n",
    "conv_image = visualkeras.layered_view(\n",
    "    model,\n",
    "    font=font,\n",
    "    padding=30,\n",
    "    index_ignore=list(range(6)) + list(range(31, 50)),\n",
    "    scale_xy=12, \n",
    "    spacing=40,\n",
    "    text_callable=text_callable,\n",
    ")\n",
    "\n",
    "dense_image = visualkeras.layered_view(\n",
    "    model,\n",
    "    font=font,\n",
    "    padding=40,\n",
    "    index_ignore=range(31),\n",
    "    scale_xy=5,\n",
    "    spacing=30,\n",
    "    text_callable=text_callable,\n",
    ")\n",
    "\n",
    "conv_image.paste(dense_image, (\n",
    "    conv_image.size[0] - dense_image.size[0] - 50,\n",
    "    conv_image.size[1] - dense_image.size[1]\n",
    "))\n",
    "conv_image.paste(inputs_image, (\n",
    "    conv_image.size[0] - inputs_image.size[0] - 50, \n",
    "    0\n",
    "))\n",
    "conv_image.save(figures_dir.joinpath('model_layered_view.png'))\n",
    "conv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c9a82d-ed98-4153-8906-6635cbef92b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec033511-4e5b-4abc-a842-c3956f61f002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28951bf1-b6f9-4cff-a551-5ddf0dbee19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.font_manager import findSystemFonts\n",
    "# system_fonts = findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "# [print(f) for f in system_fonts if 'serif' in f.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5552b-bc68-4d42-b951-5fdc2111af12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
