{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56864ab8-7d96-41fb-b882-1f24c79d6d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from importlib import reload\n",
    "import sentinel_utils\n",
    "import best_model_creator\n",
    "from data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089e3439-190d-427f-9129-c32e225ce771",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(sentinel_utils)\n",
    "\n",
    "model_dir = Path('models', 'selected_model')\n",
    "\n",
    "utils = sentinel_utils.SentinelUtils(\n",
    "    min_occurrences=20000,\n",
    ")\n",
    "\n",
    "selected_classes = utils.get_processed_labels()\n",
    "\n",
    "training_years = '2017_2018_2019'\n",
    "data_summary = utils.get_data_summary(\n",
    "    selected_classes, \n",
    "    training_years=training_years,\n",
    "    overwrite_existing=False\n",
    ")\n",
    "\n",
    "model_parent_dir = Path('models')\n",
    "model_dir = model_parent_dir.joinpath('best_model')\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "params = dict(\n",
    "    selected_classes=selected_classes,\n",
    "    data_summary=data_summary,\n",
    "    model_dir=model_dir,\n",
    "    batch_size=64,\n",
    "    years=training_years,\n",
    "    epochs=30,\n",
    "    overwrite=False,\n",
    "    verbose=1,\n",
    "    print_log=0,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7497d72e-0350-4941-b55e-800196972d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(best_model_creator)\n",
    "model, testing_generator = best_model_creator.KerasModelCreator(**params).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f4ad3c-7411-42a0-aae7-81782a8f2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = model_dir.joinpath('testing_gen_eval.npy')\n",
    "if save_path.is_file():\n",
    "    y_pred = np.load(save_path)\n",
    "else:\n",
    "    y_pred = model.predict(testing_generator)\n",
    "    np.save(save_path, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce79907d-25ac-4fef-ab89-2f5eefddc465",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf.keras.metrics.FBetaScore(\n",
    "        average=None,\n",
    "        beta=2.0,\n",
    "        threshold=0.5,\n",
    "        name='f2_score'\n",
    "    ),\n",
    "    tf.keras.metrics.FBetaScore(\n",
    "        average=None,\n",
    "        beta=1.0,\n",
    "        threshold=0.5,\n",
    "        name='f1_score'\n",
    "    ),\n",
    "]\n",
    "\n",
    "y_true_indices = testing_generator.all_IDs[:y_pred.shape[0]].tolist()\n",
    "y_true = selected_classes.filter(items=y_true_indices , axis=0)\n",
    "\n",
    "results = {}\n",
    "for m in metrics:\n",
    "    m.update_state(\n",
    "        y_true, \n",
    "        y_pred\n",
    "    )\n",
    "    results[m.name] = m.result().numpy()\n",
    "\n",
    "metrics = {\n",
    "    'recall': tf.keras.metrics.Recall,\n",
    "    'precision': tf.keras.metrics.Precision\n",
    "}\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "    m_results = []\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        m = metric(class_id=i, thresholds=0.5)\n",
    "        m.update_state(\n",
    "            selected_classes.filter(items=y_true_indices , axis=0), \n",
    "            y_pred\n",
    "        )\n",
    "        m_results.append(m.result().numpy())\n",
    "    results[name] = m_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b1b0f6f-034d-4e0e-bb60-cc55e61403fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f2_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>eval_count</th>\n",
       "      <th>train_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pinus</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4982</td>\n",
       "      <td>113811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Picea</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3389</td>\n",
       "      <td>75100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quercus</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3681</td>\n",
       "      <td>83306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fagus</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1528</td>\n",
       "      <td>34325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betula</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1840</td>\n",
       "      <td>40407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraxinus</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>872</td>\n",
       "      <td>20016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acer</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.41</td>\n",
       "      <td>866</td>\n",
       "      <td>19588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f2_score  f1_score  recall  precision  eval_count  train_count\n",
       "Pinus         0.82      0.81    0.82       0.79        4982       113811\n",
       "Picea         0.79      0.78    0.79       0.78        3389        75100\n",
       "Quercus       0.75      0.75    0.74       0.75        3681        83306\n",
       "Fagus         0.59      0.62    0.58       0.68        1528        34325\n",
       "Betula        0.49      0.53    0.46       0.62        1840        40407\n",
       "Fraxinus      0.25      0.30    0.22       0.45         872        20016\n",
       "Acer          0.11      0.15    0.09       0.41         866        19588"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    results, \n",
    "    index=selected_classes.columns,\n",
    ")\n",
    "df['eval_count'] = y_true.sum().astype(int)\n",
    "df['train_count'] = (\n",
    "    selected_classes\n",
    "    .loc[selected_classes.index.difference(y_true_indices)]\n",
    "    .sum()\n",
    "    .astype(int)\n",
    ")\n",
    "df.round(2).sort_values('f2_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae67355-6987-4f76-8a0b-da66ae9f0ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a528144-c9e2-4ec6-a322-0321aa9b2341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
