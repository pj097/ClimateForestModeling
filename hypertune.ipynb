{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc611d4-bd39-465c-8ad1-162c494f92e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.initializers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from importlib import reload\n",
    "import sentinel_utils\n",
    "import plot_utils\n",
    "from data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e411cbb-dee7-49ec-ba25-1a1f447af66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    prc = tf.keras.metrics.AUC(name='prc', curve='PR')\n",
    "\n",
    "    f1_scores = []\n",
    "    for average in ['micro', 'macro', 'weighted']:\n",
    "        f1_scores.append(\n",
    "            tf.keras.metrics.F1Score(\n",
    "                average=average, threshold=0.5, name=f'{average}f1score')\n",
    "        )\n",
    "    metrics = [\n",
    "        'accuracy', 'recall', 'precision', 'auc', prc\n",
    "    ] + f1_scores\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01282dc-921d-4d01-a27c-c4a550e1d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildHyperModel(kt.HyperModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        vars(self).update(kwargs)\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def build(self, hp):\n",
    "        sentinel_10m_input = Input((100, 100, 2))\n",
    "        sentinel_20m_input = Input((50, 50, 2))\n",
    "        \n",
    "        x = concatenate([sentinel_10m_input, UpSampling2D(2)(sentinel_20m_input)])\n",
    "        filter_power = hp.Int(\n",
    "            'filters_power', min_value=3, max_value=7, step=1\n",
    "        )\n",
    "        for filters_scale in [2**x for x in range(filter_power+1)]:\n",
    "            x = Conv2D(\n",
    "                filters=filters_scale,\n",
    "                kernel_size=hp.Int('kernel_size', min_value=3, max_value=7, step=2),\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "            )(x)\n",
    "            x = MaxPooling2D(pool_size=2, strides=2, padding='same')(x)    \n",
    "            x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "\n",
    "        units_power = hp.Int(\n",
    "            'units_power', min_value=4, max_value=8, step=1\n",
    "        )\n",
    "        for units_scale in reversed([2**x for x in range(filter_power+1)]):\n",
    "            x = Dense(units_scale, activation='relu')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "        x = Dropout(hp.Float('dropout_rate', min_value=0.0, max_value=0.8, step=0.1))(x)\n",
    "\n",
    "        if self.output_bias:\n",
    "            output_bias = tf.keras.initializers.Constant(self.output_bias)\n",
    "        else:\n",
    "            output_bias = None\n",
    "\n",
    "        outputs = Dense(\n",
    "            self.output_shape,\n",
    "            bias_initializer=output_bias,\n",
    "            activation='sigmoid',   \n",
    "        )(x)\n",
    "\n",
    "        m = tf.keras.models.Model(\n",
    "            inputs=[sentinel_10m_input, sentinel_20m_input], \n",
    "            outputs=outputs\n",
    "        )\n",
    "\n",
    "        m.compile(\n",
    "            optimizer=hp.Choice('optimizer', ['adam', 'sgd']), \n",
    "            loss=self.loss, metrics=self.metrics)\n",
    "        \n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d4be11-8df6-424a-902b-1eb7820d10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(sentinel_utils)\n",
    "\n",
    "model_dir = Path('models', 'selected_model')\n",
    "shards_dir = Path.home().joinpath('sentinel_data', 'shards')\n",
    "\n",
    "utils = sentinel_utils.SentinelUtils(min_occurrences=20000)\n",
    "\n",
    "selected_classes = utils.get_processed_labels()\n",
    "\n",
    "data_summary = utils.get_data_summary(\n",
    "    shards_dir, selected_classes, overwrite_existing=False\n",
    ")\n",
    "\n",
    "loss = 'binary_crossentropy'\n",
    "\n",
    "params = dict(\n",
    "    loss=loss,\n",
    "    shards_dir=shards_dir,\n",
    "    selected_classes=selected_classes,\n",
    "    data_summary=data_summary,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016b0cf-fd75-4867-a8b2-6f532b25767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 04m 42s]\n",
      "val_recall: 0.4115864336490631\n",
      "\n",
      "Best val_recall So Far: 0.4383960962295532\n",
      "Total elapsed time: 00h 23m 32s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "3                 |7                 |filters_scale\n",
      "7                 |7                 |kernel_size\n",
      "5                 |8                 |units_power\n",
      "0.1               |0.1               |dropout_rate\n",
      "sgd               |adam              |optimizer\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "4                 |4                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "\u001b[1m7100/7100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 19ms/step - accuracy: 0.2821 - auc: 0.6990 - loss: 0.5209 - macrof1score: 0.0729 - microf1score: 0.1562 - prc: 0.4373 - precision: 0.3627 - recall: 0.0386 - weightedf1score: 0.1318 - val_accuracy: 0.2743 - val_auc: 0.7121 - val_loss: 0.6201 - val_macrof1score: 0.1675 - val_microf1score: 0.4510 - val_prc: 0.4169 - val_precision: 0.4192 - val_recall: 0.4879 - val_weightedf1score: 0.2934\n",
      "Epoch 2/2\n",
      "\u001b[1m3352/7100\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 18ms/step - accuracy: 0.2852 - auc: 0.7178 - loss: 0.4982 - macrof1score: 0.0921 - microf1score: 0.3467 - prc: 0.4202 - precision: 0.5027 - recall: 0.2646 - weightedf1score: 0.1899"
     ]
    }
   ],
   "source": [
    "training_ids, test_ids = train_test_split(\n",
    "    selected_classes.index, test_size=10000, random_state=42\n",
    ")\n",
    "\n",
    "training_generator = DataGenerator(training_ids, shuffle=True, **params)\n",
    "testing_generator = DataGenerator(test_ids, shuffle=False, **params)\n",
    "\n",
    "metrics = get_metrics()\n",
    "\n",
    "hypermodel = BuildHyperModel(**dict(\n",
    "    output_shape=selected_classes.shape[1], \n",
    "    metrics=metrics, \n",
    "    loss=loss,\n",
    "    output_bias=data_summary['initial_bias']\n",
    "))\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel,\n",
    "    objective=kt.Objective('val_recall', direction='max'),\n",
    "    directory=Path('trials'),\n",
    "    project_name='hyperband',\n",
    "    overwrite=True\n",
    ")\n",
    "     \n",
    "tuner.search(\n",
    "    x=training_generator,\n",
    "    validation_data=testing_generator,\n",
    "    class_weight=data_summary['class_weights'],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5474a85-ef57-407b-a568-6fb6b940958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(keras_model_creator)\n",
    "model, testing_generator = keras_model_creator.KerasModelCreator(**params).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5da23-ab39-4f18-aa6a-b249e4beadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e4320-e4fe-41f2-95ef-74268cf2479c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b338c2a0-5c4e-4c59-acd4-25f2a07358a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79e0bb-81e2-4f5c-8a37-4d3b30829417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
